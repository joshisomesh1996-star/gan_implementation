{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F7huhCdq60NA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import os\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "z_dim = 100  # Size of the noise vector\n",
        "image_size = 28\n",
        "channels = 1\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "beta1 = 0.5  # Adam optimizer beta1\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Create output folder\n",
        "os.makedirs(\"generated_images\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])  # Normalize between [-1, 1]\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('.', train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "xp_G9DoA7yTv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "752c14ca-b2b0-4e45-92f1-4288028e4ef1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 58.4MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.83MB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 14.8MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 7.84MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim):\n",
        "        super(Generator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Input: (N, z_dim, 1, 1)\n",
        "            nn.ConvTranspose2d(z_dim, 256, 7, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()  # Output range [-1, 1]\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)"
      ],
      "metadata": {
        "id": "56tgfJEr706L"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # Input: (N, 1, 28, 28)\n",
        "            nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(128 * 7 * 7, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img):\n",
        "        return self.net(img)"
      ],
      "metadata": {
        "id": "HkaE-2TM75r2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(z_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Binary Cross Entropy loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "nrN7ULtC78On"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(epoch):\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(64, z_dim, 1, 1).to(device)\n",
        "        fake_images = generator(z)\n",
        "        fake_images = fake_images * 0.5 + 0.5  # Denormalize to [0,1]\n",
        "        save_image(fake_images, f\"generated_images/sample_epoch_{epoch}.png\", nrow=8)\n",
        "    generator.train()"
      ],
      "metadata": {
        "id": "g2_yjsuO7_vf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3  # Generator updates per iteration\n",
        "p = 1  # Discriminator updates per iteration"
      ],
      "metadata": {
        "id": "FnT4Il_S-2UJ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    for i, (real_imgs, _) in enumerate(train_loader):\n",
        "        batch_size_curr = real_imgs.size(0)\n",
        "        real_imgs = real_imgs.to(device)\n",
        "\n",
        "        real = torch.ones(batch_size_curr, 1, device=device)\n",
        "        fake = torch.zeros(batch_size_curr, 1, device=device)\n",
        "\n",
        "        ### ---- Train Discriminator p times ---- ###\n",
        "        for _ in range(p):\n",
        "            z = torch.randn(batch_size_curr, z_dim, 1, 1, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            # Real\n",
        "            real_validity = discriminator(real_imgs)\n",
        "            d_real_loss = criterion(real_validity, real)\n",
        "\n",
        "            # Fake\n",
        "            fake_validity = discriminator(fake_imgs.detach())\n",
        "            d_fake_loss = criterion(fake_validity, fake)\n",
        "\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "        ### ---- Train Generator k times ---- ###\n",
        "        for _ in range(k):\n",
        "            z = torch.randn(batch_size_curr, z_dim, 1, 1, device=device)\n",
        "            fake_imgs = generator(z)\n",
        "\n",
        "            validity = discriminator(fake_imgs)\n",
        "            g_loss = criterion(validity, real)  # fool D → label as real\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        if i % 200 == 0:\n",
        "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(train_loader)}] \"\n",
        "                  f\"D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Save sample images\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(64, z_dim, 1, 1, device=device)\n",
        "        samples = generator(z)\n",
        "        samples = samples * 0.5 + 0.5  # Denormalize\n",
        "        save_image(samples, f\"generated_images/epoch_{epoch}.png\", nrow=8)\n",
        "    generator.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiXv5iy88E_0",
        "outputId": "d83994cb-9e3b-444a-82fb-d5fe7f7185fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] [Batch 0/469] D Loss: 1.5404 | G Loss: 0.3703\n",
            "[Epoch 1/50] [Batch 200/469] D Loss: 1.6446 | G Loss: 0.7118\n",
            "[Epoch 1/50] [Batch 400/469] D Loss: 1.1452 | G Loss: 0.7580\n",
            "[Epoch 2/50] [Batch 0/469] D Loss: 1.1033 | G Loss: 0.7056\n",
            "[Epoch 2/50] [Batch 200/469] D Loss: 1.0716 | G Loss: 1.0414\n",
            "[Epoch 2/50] [Batch 400/469] D Loss: 1.0872 | G Loss: 0.9782\n",
            "[Epoch 3/50] [Batch 0/469] D Loss: 1.0503 | G Loss: 1.1495\n",
            "[Epoch 3/50] [Batch 200/469] D Loss: 1.1115 | G Loss: 0.8858\n",
            "[Epoch 3/50] [Batch 400/469] D Loss: 1.1566 | G Loss: 0.6472\n",
            "[Epoch 4/50] [Batch 0/469] D Loss: 1.0953 | G Loss: 1.0072\n",
            "[Epoch 4/50] [Batch 200/469] D Loss: 1.0822 | G Loss: 0.8813\n",
            "[Epoch 4/50] [Batch 400/469] D Loss: 1.1214 | G Loss: 0.8801\n",
            "[Epoch 5/50] [Batch 0/469] D Loss: 1.1151 | G Loss: 1.0809\n",
            "[Epoch 5/50] [Batch 200/469] D Loss: 1.1926 | G Loss: 1.1789\n",
            "[Epoch 5/50] [Batch 400/469] D Loss: 1.1351 | G Loss: 0.9392\n",
            "[Epoch 6/50] [Batch 0/469] D Loss: 1.0255 | G Loss: 1.1095\n",
            "[Epoch 6/50] [Batch 200/469] D Loss: 1.1827 | G Loss: 1.1927\n",
            "[Epoch 6/50] [Batch 400/469] D Loss: 1.1880 | G Loss: 0.5729\n",
            "[Epoch 7/50] [Batch 0/469] D Loss: 1.2081 | G Loss: 1.0017\n",
            "[Epoch 7/50] [Batch 200/469] D Loss: 1.0313 | G Loss: 0.7391\n",
            "[Epoch 7/50] [Batch 400/469] D Loss: 1.1772 | G Loss: 0.5549\n",
            "[Epoch 8/50] [Batch 0/469] D Loss: 1.2121 | G Loss: 0.7599\n",
            "[Epoch 8/50] [Batch 200/469] D Loss: 1.2753 | G Loss: 0.6731\n",
            "[Epoch 8/50] [Batch 400/469] D Loss: 1.1088 | G Loss: 1.1731\n",
            "[Epoch 9/50] [Batch 0/469] D Loss: 1.0911 | G Loss: 0.9068\n",
            "[Epoch 9/50] [Batch 200/469] D Loss: 1.1142 | G Loss: 1.0598\n",
            "[Epoch 9/50] [Batch 400/469] D Loss: 1.1067 | G Loss: 1.2388\n",
            "[Epoch 10/50] [Batch 0/469] D Loss: 1.2131 | G Loss: 0.6826\n",
            "[Epoch 10/50] [Batch 200/469] D Loss: 1.0726 | G Loss: 0.9380\n",
            "[Epoch 10/50] [Batch 400/469] D Loss: 1.0236 | G Loss: 1.0059\n",
            "[Epoch 11/50] [Batch 0/469] D Loss: 1.1498 | G Loss: 0.9976\n",
            "[Epoch 11/50] [Batch 200/469] D Loss: 1.0793 | G Loss: 1.5077\n",
            "[Epoch 11/50] [Batch 400/469] D Loss: 1.1557 | G Loss: 1.1648\n",
            "[Epoch 12/50] [Batch 0/469] D Loss: 1.0759 | G Loss: 1.2237\n",
            "[Epoch 12/50] [Batch 200/469] D Loss: 1.0819 | G Loss: 0.6474\n",
            "[Epoch 12/50] [Batch 400/469] D Loss: 1.1433 | G Loss: 0.7631\n",
            "[Epoch 13/50] [Batch 0/469] D Loss: 1.0633 | G Loss: 0.9248\n",
            "[Epoch 13/50] [Batch 200/469] D Loss: 1.1197 | G Loss: 1.2415\n",
            "[Epoch 13/50] [Batch 400/469] D Loss: 1.0480 | G Loss: 0.8256\n",
            "[Epoch 14/50] [Batch 0/469] D Loss: 1.1774 | G Loss: 1.1179\n",
            "[Epoch 14/50] [Batch 200/469] D Loss: 1.1035 | G Loss: 1.5876\n",
            "[Epoch 14/50] [Batch 400/469] D Loss: 1.2888 | G Loss: 1.3334\n",
            "[Epoch 15/50] [Batch 0/469] D Loss: 1.0893 | G Loss: 1.3045\n",
            "[Epoch 15/50] [Batch 200/469] D Loss: 1.0443 | G Loss: 0.8262\n",
            "[Epoch 15/50] [Batch 400/469] D Loss: 1.0505 | G Loss: 1.2372\n",
            "[Epoch 16/50] [Batch 0/469] D Loss: 1.1400 | G Loss: 1.0131\n",
            "[Epoch 16/50] [Batch 200/469] D Loss: 1.0502 | G Loss: 1.7194\n",
            "[Epoch 16/50] [Batch 400/469] D Loss: 1.0977 | G Loss: 1.5026\n",
            "[Epoch 17/50] [Batch 0/469] D Loss: 1.1301 | G Loss: 0.6398\n",
            "[Epoch 17/50] [Batch 200/469] D Loss: 1.0811 | G Loss: 1.0880\n",
            "[Epoch 17/50] [Batch 400/469] D Loss: 0.9892 | G Loss: 1.0366\n",
            "[Epoch 18/50] [Batch 0/469] D Loss: 1.2593 | G Loss: 1.3443\n",
            "[Epoch 18/50] [Batch 200/469] D Loss: 1.1661 | G Loss: 0.9938\n",
            "[Epoch 18/50] [Batch 400/469] D Loss: 1.1580 | G Loss: 1.2513\n",
            "[Epoch 19/50] [Batch 0/469] D Loss: 1.2874 | G Loss: 1.4205\n",
            "[Epoch 19/50] [Batch 200/469] D Loss: 1.0758 | G Loss: 1.1781\n",
            "[Epoch 19/50] [Batch 400/469] D Loss: 1.2660 | G Loss: 0.5967\n",
            "[Epoch 20/50] [Batch 0/469] D Loss: 1.1092 | G Loss: 0.9604\n",
            "[Epoch 20/50] [Batch 200/469] D Loss: 1.1220 | G Loss: 0.7818\n",
            "[Epoch 20/50] [Batch 400/469] D Loss: 1.2496 | G Loss: 1.2350\n",
            "[Epoch 21/50] [Batch 0/469] D Loss: 1.1180 | G Loss: 0.9769\n",
            "[Epoch 21/50] [Batch 200/469] D Loss: 1.1697 | G Loss: 1.4032\n",
            "[Epoch 21/50] [Batch 400/469] D Loss: 1.1117 | G Loss: 1.2702\n",
            "[Epoch 22/50] [Batch 0/469] D Loss: 1.0901 | G Loss: 1.1905\n",
            "[Epoch 22/50] [Batch 200/469] D Loss: 1.1364 | G Loss: 0.8024\n",
            "[Epoch 22/50] [Batch 400/469] D Loss: 1.0303 | G Loss: 1.0335\n",
            "[Epoch 23/50] [Batch 0/469] D Loss: 1.0152 | G Loss: 0.7549\n",
            "[Epoch 23/50] [Batch 200/469] D Loss: 1.1013 | G Loss: 1.4610\n",
            "[Epoch 23/50] [Batch 400/469] D Loss: 1.2446 | G Loss: 0.8382\n",
            "[Epoch 24/50] [Batch 0/469] D Loss: 1.0655 | G Loss: 0.9100\n",
            "[Epoch 24/50] [Batch 200/469] D Loss: 1.0450 | G Loss: 0.9361\n",
            "[Epoch 24/50] [Batch 400/469] D Loss: 1.0976 | G Loss: 0.7114\n",
            "[Epoch 25/50] [Batch 0/469] D Loss: 1.0580 | G Loss: 0.9367\n",
            "[Epoch 25/50] [Batch 200/469] D Loss: 1.2313 | G Loss: 1.5931\n",
            "[Epoch 25/50] [Batch 400/469] D Loss: 1.0557 | G Loss: 1.1897\n",
            "[Epoch 26/50] [Batch 0/469] D Loss: 1.1336 | G Loss: 1.0888\n",
            "[Epoch 26/50] [Batch 200/469] D Loss: 1.1138 | G Loss: 0.7838\n",
            "[Epoch 26/50] [Batch 400/469] D Loss: 1.0508 | G Loss: 1.3942\n",
            "[Epoch 27/50] [Batch 0/469] D Loss: 1.0909 | G Loss: 1.2030\n",
            "[Epoch 27/50] [Batch 200/469] D Loss: 1.0925 | G Loss: 1.3044\n",
            "[Epoch 27/50] [Batch 400/469] D Loss: 1.2362 | G Loss: 1.5915\n",
            "[Epoch 28/50] [Batch 0/469] D Loss: 1.1307 | G Loss: 1.4175\n",
            "[Epoch 28/50] [Batch 200/469] D Loss: 1.2071 | G Loss: 0.6727\n",
            "[Epoch 28/50] [Batch 400/469] D Loss: 1.2409 | G Loss: 0.7084\n",
            "[Epoch 29/50] [Batch 0/469] D Loss: 1.0843 | G Loss: 1.5840\n",
            "[Epoch 29/50] [Batch 200/469] D Loss: 1.0608 | G Loss: 1.2058\n",
            "[Epoch 29/50] [Batch 400/469] D Loss: 1.1231 | G Loss: 1.3222\n",
            "[Epoch 30/50] [Batch 0/469] D Loss: 1.0813 | G Loss: 1.2986\n",
            "[Epoch 30/50] [Batch 200/469] D Loss: 1.0353 | G Loss: 1.1550\n",
            "[Epoch 30/50] [Batch 400/469] D Loss: 1.2269 | G Loss: 1.6205\n",
            "[Epoch 31/50] [Batch 0/469] D Loss: 1.1238 | G Loss: 0.7374\n",
            "[Epoch 31/50] [Batch 200/469] D Loss: 1.1202 | G Loss: 1.3897\n",
            "[Epoch 31/50] [Batch 400/469] D Loss: 1.1461 | G Loss: 0.8539\n",
            "[Epoch 32/50] [Batch 0/469] D Loss: 1.1784 | G Loss: 1.1656\n",
            "[Epoch 32/50] [Batch 200/469] D Loss: 1.0896 | G Loss: 0.8410\n",
            "[Epoch 32/50] [Batch 400/469] D Loss: 1.0771 | G Loss: 0.8446\n",
            "[Epoch 33/50] [Batch 0/469] D Loss: 1.1322 | G Loss: 0.7656\n",
            "[Epoch 33/50] [Batch 200/469] D Loss: 1.2051 | G Loss: 1.4147\n",
            "[Epoch 33/50] [Batch 400/469] D Loss: 1.0869 | G Loss: 0.9965\n",
            "[Epoch 34/50] [Batch 0/469] D Loss: 1.1105 | G Loss: 1.0527\n",
            "[Epoch 34/50] [Batch 200/469] D Loss: 1.0227 | G Loss: 0.9453\n",
            "[Epoch 34/50] [Batch 400/469] D Loss: 1.0808 | G Loss: 1.2296\n",
            "[Epoch 35/50] [Batch 0/469] D Loss: 1.0915 | G Loss: 0.8559\n",
            "[Epoch 35/50] [Batch 200/469] D Loss: 1.1467 | G Loss: 0.5866\n",
            "[Epoch 35/50] [Batch 400/469] D Loss: 1.0674 | G Loss: 0.8634\n",
            "[Epoch 36/50] [Batch 0/469] D Loss: 1.1523 | G Loss: 1.2687\n",
            "[Epoch 36/50] [Batch 200/469] D Loss: 1.1278 | G Loss: 0.7629\n",
            "[Epoch 36/50] [Batch 400/469] D Loss: 1.1165 | G Loss: 1.5394\n",
            "[Epoch 37/50] [Batch 0/469] D Loss: 1.0983 | G Loss: 0.7618\n",
            "[Epoch 37/50] [Batch 200/469] D Loss: 1.1005 | G Loss: 1.1198\n",
            "[Epoch 37/50] [Batch 400/469] D Loss: 1.2514 | G Loss: 1.5165\n",
            "[Epoch 38/50] [Batch 0/469] D Loss: 1.1650 | G Loss: 0.8144\n",
            "[Epoch 38/50] [Batch 200/469] D Loss: 1.0973 | G Loss: 0.7363\n",
            "[Epoch 38/50] [Batch 400/469] D Loss: 1.3062 | G Loss: 1.4189\n",
            "[Epoch 39/50] [Batch 0/469] D Loss: 1.0808 | G Loss: 0.9745\n",
            "[Epoch 39/50] [Batch 200/469] D Loss: 1.0464 | G Loss: 1.5064\n",
            "[Epoch 39/50] [Batch 400/469] D Loss: 1.1645 | G Loss: 1.2728\n",
            "[Epoch 40/50] [Batch 0/469] D Loss: 1.0475 | G Loss: 1.4890\n",
            "[Epoch 40/50] [Batch 200/469] D Loss: 1.0961 | G Loss: 0.6917\n",
            "[Epoch 40/50] [Batch 400/469] D Loss: 1.3857 | G Loss: 1.6497\n",
            "[Epoch 41/50] [Batch 0/469] D Loss: 1.1656 | G Loss: 0.6531\n",
            "[Epoch 41/50] [Batch 200/469] D Loss: 1.1570 | G Loss: 1.1119\n",
            "[Epoch 41/50] [Batch 400/469] D Loss: 1.0826 | G Loss: 1.0068\n",
            "[Epoch 42/50] [Batch 0/469] D Loss: 1.1481 | G Loss: 0.5710\n",
            "[Epoch 42/50] [Batch 200/469] D Loss: 1.1583 | G Loss: 1.0006\n",
            "[Epoch 42/50] [Batch 400/469] D Loss: 1.3978 | G Loss: 1.4965\n",
            "[Epoch 43/50] [Batch 0/469] D Loss: 1.0913 | G Loss: 0.7373\n",
            "[Epoch 43/50] [Batch 200/469] D Loss: 1.1250 | G Loss: 1.2715\n",
            "[Epoch 43/50] [Batch 400/469] D Loss: 1.1800 | G Loss: 1.0098\n",
            "[Epoch 44/50] [Batch 0/469] D Loss: 1.0963 | G Loss: 1.2927\n",
            "[Epoch 44/50] [Batch 200/469] D Loss: 1.2407 | G Loss: 1.3984\n",
            "[Epoch 44/50] [Batch 400/469] D Loss: 1.0831 | G Loss: 0.8139\n",
            "[Epoch 45/50] [Batch 0/469] D Loss: 1.0487 | G Loss: 1.0917\n",
            "[Epoch 45/50] [Batch 200/469] D Loss: 1.1076 | G Loss: 1.1532\n",
            "[Epoch 45/50] [Batch 400/469] D Loss: 1.0208 | G Loss: 0.9214\n",
            "[Epoch 46/50] [Batch 0/469] D Loss: 0.9731 | G Loss: 1.7205\n",
            "[Epoch 46/50] [Batch 200/469] D Loss: 1.0811 | G Loss: 0.8097\n",
            "[Epoch 46/50] [Batch 400/469] D Loss: 1.0872 | G Loss: 0.9558\n",
            "[Epoch 47/50] [Batch 0/469] D Loss: 1.2316 | G Loss: 0.8682\n",
            "[Epoch 47/50] [Batch 200/469] D Loss: 1.1640 | G Loss: 0.6988\n",
            "[Epoch 47/50] [Batch 400/469] D Loss: 1.1484 | G Loss: 1.1368\n",
            "[Epoch 48/50] [Batch 0/469] D Loss: 1.1480 | G Loss: 1.0871\n",
            "[Epoch 48/50] [Batch 200/469] D Loss: 1.0813 | G Loss: 0.7488\n",
            "[Epoch 48/50] [Batch 400/469] D Loss: 0.9919 | G Loss: 1.1630\n",
            "[Epoch 49/50] [Batch 0/469] D Loss: 1.1174 | G Loss: 1.0710\n",
            "[Epoch 49/50] [Batch 200/469] D Loss: 1.1022 | G Loss: 0.7483\n",
            "[Epoch 49/50] [Batch 400/469] D Loss: 1.2121 | G Loss: 0.7714\n",
            "[Epoch 50/50] [Batch 0/469] D Loss: 1.0456 | G Loss: 1.2707\n",
            "[Epoch 50/50] [Batch 200/469] D Loss: 1.1255 | G Loss: 0.5681\n",
            "[Epoch 50/50] [Batch 400/469] D Loss: 1.1643 | G Loss: 1.1457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "def generate_images_dcgan_individually(generator, num_samples=512, save_dir=\"generated_images\", prefix=\"img\"):\n",
        "    \"\"\"\n",
        "    Generates images using a DCGAN generator and saves each one individually.\n",
        "\n",
        "    Args:\n",
        "        generator (nn.Module): Trained DCGAN generator model\n",
        "        num_samples (int): Number of images to generate\n",
        "        save_dir (str): Directory to save generated images\n",
        "        prefix (str): Filename prefix for saved images\n",
        "    \"\"\"\n",
        "    generator.eval()\n",
        "    z = torch.randn(num_samples, z_dim, 1, 1).to(device)\n",
        "\n",
        "    # Ensure output directory exists\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        gen_imgs = generator(z)\n",
        "        gen_imgs = gen_imgs * 0.5 + 0.5  # Denormalize from [-1, 1] to [0, 1]\n",
        "\n",
        "        for i, img in enumerate(gen_imgs):\n",
        "            save_path = os.path.join(save_dir, f\"{prefix}_{i:04d}.png\")\n",
        "            save_image(img, save_path)\n",
        "\n",
        "    print(f\"Saved {num_samples} images to '{save_dir}'\")\n",
        "    return gen_imgs"
      ],
      "metadata": {
        "id": "zeTqETdO8OYH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generate_images_dcgan_individually(generator, num_samples=1024)"
      ],
      "metadata": {
        "id": "Xm9p2js08T5F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d6c8f9c-a9ca-43e7-eca9-08c7a9a53ab0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 1024 images to 'generated_images'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00]]],\n",
              "\n",
              "\n",
              "        [[[4.0561e-05, 1.9363e-04, 2.8775e-03,  ..., 7.1526e-07,\n",
              "           1.3059e-04, 6.4731e-05],\n",
              "          [4.3213e-06, 3.4660e-05, 9.6858e-06,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [5.6624e-07, 1.2368e-05, 2.5123e-05,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [1.8686e-05, 3.5763e-07, 4.6492e-06,  ..., 2.7993e-04,\n",
              "           1.9991e-04, 6.2239e-04],\n",
              "          [0.0000e+00, 0.0000e+00, 2.9802e-08,  ..., 2.5659e-03,\n",
              "           2.1822e-03, 2.8571e-04],\n",
              "          [0.0000e+00, 0.0000e+00, 2.0862e-07,  ..., 6.0911e-03,\n",
              "           1.2108e-03, 1.4535e-04]]],\n",
              "\n",
              "\n",
              "        [[[8.5813e-04, 1.1197e-03, 8.5658e-04,  ..., 1.3709e-06,\n",
              "           4.0531e-06, 2.5213e-05],\n",
              "          [4.5300e-06, 6.6459e-06, 3.2783e-07,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.7107e-05, 1.7881e-07, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 2.0146e-05,\n",
              "           7.9572e-06, 3.2365e-05],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 2.9802e-08],\n",
              "          [1.5795e-06, 2.9802e-08, 0.0000e+00,  ..., 8.9407e-08,\n",
              "           1.4901e-07, 1.9372e-06]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[2.6008e-04, 3.4451e-05, 2.2352e-05,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.9965e-03, 2.4664e-04, 7.2628e-05,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.3711e-03, 1.2604e-03, 1.4343e-03,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.1921e-07],\n",
              "          ...,\n",
              "          [8.1450e-05, 6.6063e-04, 3.1844e-04,  ..., 5.1260e-06,\n",
              "           2.9802e-08, 6.2585e-07],\n",
              "          [4.0114e-05, 3.7822e-04, 1.4681e-03,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [1.1057e-05, 5.7311e-03, 3.6412e-04,  ..., 5.9605e-08,\n",
              "           2.9802e-08, 5.9605e-08]]],\n",
              "\n",
              "\n",
              "        [[[1.5914e-03, 4.5419e-05, 2.1806e-04,  ..., 4.0010e-04,\n",
              "           1.4365e-04, 5.3149e-04],\n",
              "          [2.5928e-06, 5.9605e-08, 2.9802e-08,  ..., 1.7881e-07,\n",
              "           8.7619e-06, 5.4926e-05],\n",
              "          [4.4703e-07, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 1.7881e-07],\n",
              "          ...,\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [2.8312e-06, 5.9605e-08, 2.9802e-08,  ..., 2.9802e-08,\n",
              "           1.3113e-06, 1.2547e-05]]],\n",
              "\n",
              "\n",
              "        [[[5.6624e-06, 2.9802e-08, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 0.0000e+00],\n",
              "          ...,\n",
              "          [2.9802e-08, 2.9802e-08, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 5.9605e-08],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           0.0000e+00, 3.5763e-07],\n",
              "          [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00,\n",
              "           6.5863e-06, 1.5873e-04]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def save_random_mnist_images(save_dir=\"real_images/mnist\",\n",
        "                             num_samples=1024,\n",
        "                             prefix=\"mnist\",\n",
        "                             batch_size=128):\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "    torch.manual_seed(42)\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5,), (0.5,))\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.MNIST(root=\"./data\", train=True,\n",
        "                             transform=transform, download=True)\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    saved = 0\n",
        "    for batch_imgs, _ in loader:\n",
        "        for img in batch_imgs:\n",
        "            if saved >= num_samples:\n",
        "                print(f\"✅ Saved {num_samples} MNIST images to '{save_dir}'\")\n",
        "                return\n",
        "\n",
        "            img = img.repeat(3, 1, 1)\n",
        "            save_image(img, os.path.join(save_dir, f\"{prefix}_{saved:04d}.png\"))\n",
        "            saved += 1\n"
      ],
      "metadata": {
        "id": "ajiE24Xvisky"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p real_images/mnist\n",
        "!mkdir -p generated_images/fake"
      ],
      "metadata": {
        "id": "Omv1VSmF5eqf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_random_mnist_images(save_dir=\"real_images/mnist\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VO2nP0yZ5it8",
        "outputId": "fbbe999d-8f30-4367-e075-53d612a654fc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved 1024 MNIST images to 'real_images/mnist'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"real_images\"))          # MUST show ['mnist']\n",
        "print(os.listdir(\"real_images/mnist\")[:5])  # MUST show images\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCxwJwn65l3m",
        "outputId": "4a2e145e-56de-4701-ee24-b33466634876"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mnist_0614.png', 'mnist_0607.png', 'mnist_0610.png', 'mnist_0542.png', 'mnist_0120.png', 'mnist_0079.png', 'mnist_0609.png', 'mnist_0381.png', 'mnist_0974.png', 'mnist_0669.png', 'mnist_0437.png', 'mnist_0404.png', 'mnist_0238.png', 'mnist_0151.png', 'mnist_0130.png', 'mnist_0652.png', 'mnist_0665.png', 'mnist_0450.png', 'mnist_0195.png', 'mnist_0243.png', 'mnist_0872.png', 'mnist_0374.png', 'mnist_0915.png', 'mnist_0329.png', 'mnist_0559.png', 'mnist_0646.png', 'mnist_0225.png', 'mnist_0581.png', 'mnist_0279.png', 'mnist_0449.png', 'mnist_0034.png', 'mnist_0327.png', 'mnist_0483.png', 'mnist_0308.png', 'mnist_0842.png', 'mnist_0481.png', 'mnist_0286.png', 'mnist_0627.png', 'mnist_0923.png', 'mnist_0001.png', 'mnist_0246.png', 'mnist_0361.png', 'mnist_0075.png', 'mnist_0773.png', 'mnist_0821.png', 'mnist_0128.png', 'mnist_0537.png', 'mnist_0816.png', 'mnist_0068.png', 'mnist_0411.png', 'mnist_0865.png', 'mnist_0065.png', 'mnist_0523.png', 'mnist_0406.png', 'mnist_0794.png', 'mnist_0524.png', 'mnist_0469.png', 'mnist_0372.png', 'mnist_0240.png', 'mnist_0517.png', 'mnist_0345.png', 'mnist_0568.png', 'mnist_0455.png', 'mnist_0115.png', 'mnist_0695.png', 'mnist_0340.png', 'mnist_0435.png', 'mnist_0053.png', 'mnist_0147.png', 'mnist_0301.png', 'mnist_0977.png', 'mnist_0673.png', 'mnist_0721.png', 'mnist_0819.png', 'mnist_0212.png', 'mnist_0577.png', 'mnist_0365.png', 'mnist_0338.png', 'mnist_0649.png', 'mnist_0839.png', 'mnist_0171.png', 'mnist_0418.png', 'mnist_0463.png', 'mnist_0855.png', 'mnist_0660.png', 'mnist_0845.png', 'mnist_0315.png', 'mnist_1019.png', 'mnist_0337.png', 'mnist_0508.png', 'mnist_0602.png', 'mnist_0787.png', 'mnist_0944.png', 'mnist_0050.png', 'mnist_0677.png', 'mnist_0332.png', 'mnist_0040.png', 'mnist_0590.png', 'mnist_0954.png', 'mnist_0182.png', 'mnist_0236.png', 'mnist_0226.png', 'mnist_0300.png', 'mnist_0593.png', 'mnist_0111.png', 'mnist_0259.png', 'mnist_0575.png', 'mnist_0017.png', 'mnist_0902.png', 'mnist_0910.png', 'mnist_0881.png', 'mnist_0877.png', 'mnist_0280.png', 'mnist_0460.png', 'mnist_0328.png', 'mnist_0394.png', 'mnist_0998.png', 'mnist_0539.png', 'mnist_0733.png', 'mnist_0019.png', 'mnist_0377.png', 'mnist_1017.png', 'mnist_0805.png', 'mnist_0353.png', 'mnist_0920.png', 'mnist_1003.png', 'mnist_0579.png', 'mnist_0634.png', 'mnist_0592.png', 'mnist_0890.png', 'mnist_1010.png', 'mnist_0936.png', 'mnist_0656.png', 'mnist_0651.png', 'mnist_0892.png', 'mnist_0189.png', 'mnist_0252.png', 'mnist_0598.png', 'mnist_0764.png', 'mnist_0321.png', 'mnist_0852.png', 'mnist_0820.png', 'mnist_0808.png', 'mnist_0864.png', 'mnist_0169.png', 'mnist_0215.png', 'mnist_0908.png', 'mnist_0282.png', 'mnist_0219.png', 'mnist_0090.png', 'mnist_0703.png', 'mnist_0254.png', 'mnist_0806.png', 'mnist_0792.png', 'mnist_0160.png', 'mnist_0599.png', 'mnist_0108.png', 'mnist_0671.png', 'mnist_0769.png', 'mnist_0166.png', 'mnist_1002.png', 'mnist_0339.png', 'mnist_0563.png', 'mnist_0847.png', 'mnist_0462.png', 'mnist_0375.png', 'mnist_0771.png', 'mnist_0164.png', 'mnist_0644.png', 'mnist_0971.png', 'mnist_0421.png', 'mnist_0774.png', 'mnist_0681.png', 'mnist_0804.png', 'mnist_0601.png', 'mnist_0357.png', 'mnist_0297.png', 'mnist_0980.png', 'mnist_0772.png', 'mnist_0858.png', 'mnist_0690.png', 'mnist_1016.png', 'mnist_0479.png', 'mnist_0247.png', 'mnist_0848.png', 'mnist_0873.png', 'mnist_0594.png', 'mnist_0499.png', 'mnist_0414.png', 'mnist_0851.png', 'mnist_0863.png', 'mnist_0244.png', 'mnist_0181.png', 'mnist_0586.png', 'mnist_0869.png', 'mnist_0738.png', 'mnist_0846.png', 'mnist_0284.png', 'mnist_0573.png', 'mnist_0027.png', 'mnist_0680.png', 'mnist_0750.png', 'mnist_0335.png', 'mnist_0901.png', 'mnist_0073.png', 'mnist_0451.png', 'mnist_0072.png', 'mnist_0743.png', 'mnist_0364.png', 'mnist_0897.png', 'mnist_0078.png', 'mnist_0051.png', 'mnist_0829.png', 'mnist_0206.png', 'mnist_0143.png', 'mnist_0766.png', 'mnist_0133.png', 'mnist_0402.png', 'mnist_0722.png', 'mnist_0302.png', 'mnist_0833.png', 'mnist_0740.png', 'mnist_0737.png', 'mnist_0135.png', 'mnist_0296.png', 'mnist_0271.png', 'mnist_1022.png', 'mnist_0587.png', 'mnist_0257.png', 'mnist_0549.png', 'mnist_0498.png', 'mnist_0380.png', 'mnist_0834.png', 'mnist_0208.png', 'mnist_0801.png', 'mnist_0431.png', 'mnist_0780.png', 'mnist_0293.png', 'mnist_0763.png', 'mnist_0730.png', 'mnist_0731.png', 'mnist_0095.png', 'mnist_0097.png', 'mnist_0981.png', 'mnist_0291.png', 'mnist_0744.png', 'mnist_0516.png', 'mnist_0727.png', 'mnist_0184.png', 'mnist_0616.png', 'mnist_0428.png', 'mnist_0903.png', 'mnist_0423.png', 'mnist_0278.png', 'mnist_0057.png', 'mnist_0946.png', 'mnist_0039.png', 'mnist_0456.png', 'mnist_0618.png', 'mnist_0442.png', 'mnist_0342.png', 'mnist_0359.png', 'mnist_0972.png', 'mnist_0536.png', 'mnist_0021.png', 'mnist_0453.png', 'mnist_0025.png', 'mnist_0837.png', 'mnist_0859.png', 'mnist_0384.png', 'mnist_0522.png', 'mnist_0670.png', 'mnist_0349.png', 'mnist_0905.png', 'mnist_0752.png', 'mnist_0207.png', 'mnist_0535.png', 'mnist_0320.png', 'mnist_0063.png', 'mnist_0964.png', 'mnist_0010.png', 'mnist_0429.png', 'mnist_0416.png', 'mnist_0213.png', 'mnist_0530.png', 'mnist_0217.png', 'mnist_0299.png', 'mnist_0285.png', 'mnist_0193.png', 'mnist_0533.png', 'mnist_0082.png', 'mnist_0714.png', 'mnist_0888.png', 'mnist_0643.png', 'mnist_0631.png', 'mnist_0104.png', 'mnist_1006.png', 'mnist_0024.png', 'mnist_0636.png', 'mnist_0295.png', 'mnist_0062.png', 'mnist_0105.png', 'mnist_0269.png', 'mnist_0281.png', 'mnist_0554.png', 'mnist_0319.png', 'mnist_0043.png', 'mnist_0041.png', 'mnist_0557.png', 'mnist_1004.png', 'mnist_0032.png', 'mnist_0988.png', 'mnist_0900.png', 'mnist_0037.png', 'mnist_0261.png', 'mnist_0336.png', 'mnist_0061.png', 'mnist_0736.png', 'mnist_0647.png', 'mnist_0512.png', 'mnist_0911.png', 'mnist_0951.png', 'mnist_0185.png', 'mnist_0666.png', 'mnist_0223.png', 'mnist_0514.png', 'mnist_0922.png', 'mnist_0767.png', 'mnist_0264.png', 'mnist_0937.png', 'mnist_0742.png', 'mnist_0399.png', 'mnist_0433.png', 'mnist_0720.png', 'mnist_0976.png', 'mnist_0121.png', 'mnist_0344.png', 'mnist_1012.png', 'mnist_0979.png', 'mnist_0886.png', 'mnist_0552.png', 'mnist_0841.png', 'mnist_0251.png', 'mnist_0148.png', 'mnist_0457.png', 'mnist_0639.png', 'mnist_0351.png', 'mnist_0916.png', 'mnist_0891.png', 'mnist_0172.png', 'mnist_0490.png', 'mnist_0933.png', 'mnist_0948.png', 'mnist_0700.png', 'mnist_0044.png', 'mnist_0724.png', 'mnist_0363.png', 'mnist_0056.png', 'mnist_0478.png', 'mnist_0991.png', 'mnist_0754.png', 'mnist_0124.png', 'mnist_0049.png', 'mnist_0313.png', 'mnist_0140.png', 'mnist_0256.png', 'mnist_0775.png', 'mnist_0648.png', 'mnist_0777.png', 'mnist_0445.png', 'mnist_0701.png', 'mnist_0155.png', 'mnist_0687.png', 'mnist_0224.png', 'mnist_0545.png', 'mnist_0917.png', 'mnist_0439.png', 'mnist_0354.png', 'mnist_0392.png', 'mnist_0528.png', 'mnist_0080.png', 'mnist_0403.png', 'mnist_0465.png', 'mnist_0953.png', 'mnist_0630.png', 'mnist_0348.png', 'mnist_0495.png', 'mnist_0447.png', 'mnist_0165.png', 'mnist_0426.png', 'mnist_0222.png', 'mnist_0011.png', 'mnist_0066.png', 'mnist_0914.png', 'mnist_0996.png', 'mnist_0659.png', 'mnist_0491.png', 'mnist_0316.png', 'mnist_0580.png', 'mnist_0857.png', 'mnist_0459.png', 'mnist_0298.png', 'mnist_1009.png', 'mnist_0417.png', 'mnist_0623.png', 'mnist_0087.png', 'mnist_0919.png', 'mnist_0849.png', 'mnist_0002.png', 'mnist_0396.png', 'mnist_0112.png', 'mnist_0906.png', 'mnist_0605.png', 'mnist_0628.png', 'mnist_0218.png', 'mnist_0168.png', 'mnist_0471.png', 'mnist_0014.png', 'mnist_0501.png', 'mnist_0204.png', 'mnist_0551.png', 'mnist_1018.png', 'mnist_0844.png', 'mnist_0461.png', 'mnist_0548.png', 'mnist_0945.png', 'mnist_0211.png', 'mnist_0685.png', 'mnist_0391.png', 'mnist_0383.png', 'mnist_0294.png', 'mnist_0692.png', 'mnist_0986.png', 'mnist_0921.png', 'mnist_0485.png', 'mnist_0008.png', 'mnist_0330.png', 'mnist_0756.png', 'mnist_0868.png', 'mnist_0809.png', 'mnist_0739.png', 'mnist_0993.png', 'mnist_0410.png', 'mnist_0188.png', 'mnist_0241.png', 'mnist_0209.png', 'mnist_0957.png', 'mnist_0126.png', 'mnist_0615.png', 'mnist_0125.png', 'mnist_0434.png', 'mnist_0064.png', 'mnist_0347.png', 'mnist_0962.png', 'mnist_0889.png', 'mnist_0118.png', 'mnist_0818.png', 'mnist_0202.png', 'mnist_0982.png', 'mnist_0556.png', 'mnist_0984.png', 'mnist_0521.png', 'mnist_0970.png', 'mnist_0527.png', 'mnist_0197.png', 'mnist_0052.png', 'mnist_0030.png', 'mnist_0927.png', 'mnist_0386.png', 'mnist_0746.png', 'mnist_0853.png', 'mnist_0333.png', 'mnist_0620.png', 'mnist_0929.png', 'mnist_0655.png', 'mnist_0341.png', 'mnist_0191.png', 'mnist_0702.png', 'mnist_0360.png', 'mnist_0880.png', 'mnist_0229.png', 'mnist_0496.png', 'mnist_0633.png', 'mnist_0083.png', 'mnist_0832.png', 'mnist_0464.png', 'mnist_0879.png', 'mnist_0621.png', 'mnist_0717.png', 'mnist_0123.png', 'mnist_0935.png', 'mnist_0874.png', 'mnist_0672.png', 'mnist_0304.png', 'mnist_0350.png', 'mnist_0762.png', 'mnist_0931.png', 'mnist_0884.png', 'mnist_0871.png', 'mnist_0407.png', 'mnist_0578.png', 'mnist_0963.png', 'mnist_0422.png', 'mnist_0122.png', 'mnist_0200.png', 'mnist_0973.png', 'mnist_0091.png', 'mnist_0709.png', 'mnist_0799.png', 'mnist_0753.png', 'mnist_0292.png', 'mnist_0696.png', 'mnist_0658.png', 'mnist_0896.png', 'mnist_0934.png', 'mnist_0691.png', 'mnist_0305.png', 'mnist_0572.png', 'mnist_0640.png', 'mnist_0715.png', 'mnist_0326.png', 'mnist_0515.png', 'mnist_0127.png', 'mnist_0070.png', 'mnist_0273.png', 'mnist_0978.png', 'mnist_0412.png', 'mnist_0835.png', 'mnist_0683.png', 'mnist_0117.png', 'mnist_0798.png', 'mnist_0558.png', 'mnist_0288.png', 'mnist_0145.png', 'mnist_1015.png', 'mnist_0525.png', 'mnist_0424.png', 'mnist_0824.png', 'mnist_0467.png', 'mnist_0174.png', 'mnist_0036.png', 'mnist_0825.png', 'mnist_0382.png', 'mnist_0505.png', 'mnist_0077.png', 'mnist_0371.png', 'mnist_0540.png', 'mnist_0142.png', 'mnist_1008.png', 'mnist_0307.png', 'mnist_0274.png', 'mnist_0749.png', 'mnist_0909.png', 'mnist_0436.png', 'mnist_0003.png', 'mnist_0137.png', 'mnist_0474.png', 'mnist_0283.png', 'mnist_0882.png', 'mnist_0678.png', 'mnist_0486.png', 'mnist_0149.png', 'mnist_0020.png', 'mnist_0272.png', 'mnist_0684.png', 'mnist_0898.png', 'mnist_0507.png', 'mnist_0107.png', 'mnist_0518.png', 'mnist_0397.png', 'mnist_0306.png', 'mnist_0875.png', 'mnist_0150.png', 'mnist_0237.png', 'mnist_0275.png', 'mnist_0770.png', 'mnist_0817.png', 'mnist_0258.png', 'mnist_0006.png', 'mnist_0741.png', 'mnist_0975.png', 'mnist_0682.png', 'mnist_0735.png', 'mnist_0390.png', 'mnist_0956.png', 'mnist_0949.png', 'mnist_0811.png', 'mnist_0099.png', 'mnist_0940.png', 'mnist_0276.png', 'mnist_0928.png', 'mnist_0867.png', 'mnist_0096.png', 'mnist_0092.png', 'mnist_0925.png', 'mnist_0084.png', 'mnist_0102.png', 'mnist_0131.png', 'mnist_0045.png', 'mnist_0913.png', 'mnist_0567.png', 'mnist_0531.png', 'mnist_0776.png', 'mnist_0085.png', 'mnist_0103.png', 'mnist_0289.png', 'mnist_0664.png', 'mnist_0843.png', 'mnist_0358.png', 'mnist_0625.png', 'mnist_0786.png', 'mnist_0784.png', 'mnist_0942.png', 'mnist_0562.png', 'mnist_0719.png', 'mnist_0534.png', 'mnist_0312.png', 'mnist_0233.png', 'mnist_0472.png', 'mnist_0492.png', 'mnist_0876.png', 'mnist_0619.png', 'mnist_0487.png', 'mnist_0641.png', 'mnist_0497.png', 'mnist_0796.png', 'mnist_0711.png', 'mnist_1013.png', 'mnist_0893.png', 'mnist_0947.png', 'mnist_0484.png', 'mnist_0688.png', 'mnist_0679.png', 'mnist_0154.png', 'mnist_0480.png', 'mnist_0969.png', 'mnist_0413.png', 'mnist_0116.png', 'mnist_0132.png', 'mnist_0960.png', 'mnist_0177.png', 'mnist_0800.png', 'mnist_1020.png', 'mnist_0309.png', 'mnist_0248.png', 'mnist_0943.png', 'mnist_0425.png', 'mnist_0726.png', 'mnist_0489.png', 'mnist_0638.png', 'mnist_0745.png', 'mnist_0759.png', 'mnist_0606.png', 'mnist_0042.png', 'mnist_0303.png', 'mnist_0074.png', 'mnist_0393.png', 'mnist_0751.png', 'mnist_0179.png', 'mnist_0547.png', 'mnist_0362.png', 'mnist_0157.png', 'mnist_0831.png', 'mnist_0760.png', 'mnist_0405.png', 'mnist_0965.png', 'mnist_0370.png', 'mnist_0094.png', 'mnist_0582.png', 'mnist_0113.png', 'mnist_0693.png', 'mnist_0704.png', 'mnist', 'mnist_0190.png', 'mnist_0287.png', 'mnist_0748.png', 'mnist_0443.png', 'mnist_0667.png', 'mnist_0029.png', 'mnist_0230.png', 'mnist_0938.png', 'mnist_0387.png', 'mnist_0588.png', 'mnist_0047.png', 'mnist_0553.png', 'mnist_0009.png', 'mnist_0325.png', 'mnist_0657.png', 'mnist_0734.png', 'mnist_0783.png', 'mnist_0866.png', 'mnist_0088.png', 'mnist_0046.png', 'mnist_0795.png', 'mnist_0597.png', 'mnist_0277.png', 'mnist_0564.png', 'mnist_0331.png', 'mnist_0584.png', 'mnist_0612.png', 'mnist_0785.png', 'mnist_0093.png', 'mnist_0400.png', 'mnist_0966.png', 'mnist_0576.png', 'mnist_0797.png', 'mnist_0196.png', 'mnist_0574.png', 'mnist_0967.png', 'mnist_0409.png', 'mnist_0718.png', 'mnist_0069.png', 'mnist_0310.png', 'mnist_0067.png', 'mnist_0757.png', 'mnist_0694.png', 'mnist_0912.png', 'mnist_0138.png', 'mnist_0990.png', 'mnist_0242.png', 'mnist_0566.png', 'mnist_0961.png', 'mnist_0653.png', 'mnist_0810.png', 'mnist_0511.png', 'mnist_0186.png', 'mnist_0803.png', 'mnist_0346.png', 'mnist_0266.png', 'mnist_0860.png', 'mnist_0781.png', 'mnist_0708.png', 'mnist_0992.png', 'mnist_0216.png', 'mnist_0314.png', 'mnist_0475.png', 'mnist_0555.png', 'mnist_0234.png', 'mnist_0779.png', 'mnist_0926.png', 'mnist_0725.png', 'mnist_0987.png', 'mnist_0506.png', 'mnist_0013.png', 'mnist_0395.png', 'mnist_0789.png', 'mnist_0674.png', 'mnist_0055.png', 'mnist_1007.png', 'mnist_0782.png', 'mnist_0894.png', 'mnist_0840.png', 'mnist_0560.png', 'mnist_0378.png', 'mnist_0624.png', 'mnist_0322.png', 'mnist_0802.png', 'mnist_0510.png', 'mnist_0146.png', 'mnist_0959.png', 'mnist_0255.png', 'mnist_1021.png', 'mnist_0519.png', 'mnist_0076.png', 'mnist_0098.png', 'mnist_0401.png', 'mnist_0854.png', 'mnist_0613.png', 'mnist_0239.png', 'mnist_0617.png', 'mnist_0663.png', 'mnist_0570.png', 'mnist_0550.png', 'mnist_0334.png', 'mnist_0532.png', 'mnist_0729.png', 'mnist_0311.png', 'mnist_0629.png', 'mnist_0650.png', 'mnist_0373.png', 'mnist_0317.png', 'mnist_0198.png', 'mnist_0675.png', 'mnist_0023.png', 'mnist_1005.png', 'mnist_0571.png', 'mnist_0388.png', 'mnist_0199.png', 'mnist_0941.png', 'mnist_0939.png', 'mnist_0250.png', 'mnist_0994.png', 'mnist_0201.png', 'mnist_0502.png', 'mnist_0134.png', 'mnist_0747.png', 'mnist_0232.png', 'mnist_0119.png', 'mnist_0645.png', 'mnist_0071.png', 'mnist_0813.png', 'mnist_0907.png', 'mnist_0895.png', 'mnist_0583.png', 'mnist_0608.png', 'mnist_0529.png', 'mnist_0565.png', 'mnist_0488.png', 'mnist_0706.png', 'mnist_0440.png', 'mnist_0887.png', 'mnist_0850.png', 'mnist_0723.png', 'mnist_0765.png', 'mnist_0262.png', 'mnist_0830.png', 'mnist_0323.png', 'mnist_0543.png', 'mnist_0290.png', 'mnist_0812.png', 'mnist_0452.png', 'mnist_0114.png', 'mnist_0503.png', 'mnist_0755.png', 'mnist_0611.png', 'mnist_0343.png', 'mnist_0170.png', 'mnist_0444.png', 'mnist_0904.png', 'mnist_0183.png', 'mnist_0604.png', 'mnist_0642.png', 'mnist_0930.png', 'mnist_0033.png', 'mnist_0473.png', 'mnist_0768.png', 'mnist_0178.png', 'mnist_0778.png', 'mnist_0526.png', 'mnist_0790.png', 'mnist_0022.png', 'mnist_0538.png', 'mnist_0958.png', 'mnist_0968.png', 'mnist_0985.png', 'mnist_0398.png', 'mnist_0761.png', 'mnist_0788.png', 'mnist_0591.png', 'mnist_0018.png', 'mnist_0355.png', 'mnist_0989.png', 'mnist_1011.png', 'mnist_0885.png', 'mnist_0689.png', 'mnist_0807.png', 'mnist_0089.png', 'mnist_0466.png', 'mnist_0826.png', 'mnist_0187.png', 'mnist_0420.png', 'mnist_0318.png', 'mnist_0415.png', 'mnist_0569.png', 'mnist_0194.png', 'mnist_0791.png', 'mnist_0699.png', 'mnist_0060.png', 'mnist_0710.png', 'mnist_0697.png', 'mnist_0983.png', 'mnist_0176.png', 'mnist_0427.png', 'mnist_0448.png', 'mnist_0268.png', 'mnist_0544.png', 'mnist_0038.png', 'mnist_0136.png', 'mnist_0432.png', 'mnist_0356.png', 'mnist_0635.png', 'mnist_0366.png', 'mnist_0210.png', 'mnist_0408.png', 'mnist_0595.png', 'mnist_0668.png', 'mnist_0476.png', 'mnist_0012.png', 'mnist_0686.png', 'mnist_0500.png', 'mnist_0267.png', 'mnist_0000.png', 'mnist_0999.png', 'mnist_0822.png', 'mnist_0245.png', 'mnist_0221.png', 'mnist_0637.png', 'mnist_0368.png', 'mnist_0144.png', 'mnist_0561.png', 'mnist_0883.png', 'mnist_0054.png', 'mnist_0220.png', 'mnist_0815.png', 'mnist_0376.png', 'mnist_0173.png', 'mnist_0716.png', 'mnist_0249.png', 'mnist_0156.png', 'mnist_0758.png', 'mnist_0203.png', 'mnist_0352.png', 'mnist_1014.png', 'mnist_0438.png', 'mnist_0952.png', 'mnist_0589.png', 'mnist_0227.png', 'mnist_0823.png', 'mnist_0100.png', 'mnist_0059.png', 'mnist_0265.png', 'mnist_0379.png', 'mnist_0676.png', 'mnist_0228.png', 'mnist_0828.png', 'mnist_0367.png', 'mnist_0707.png', 'mnist_0713.png', 'mnist_1001.png', 'mnist_0698.png', 'mnist_0152.png', 'mnist_0129.png', 'mnist_0016.png', 'mnist_0622.png', 'mnist_0139.png', 'mnist_0838.png', 'mnist_0005.png', 'mnist_0048.png', 'mnist_1023.png', 'mnist_0632.png', 'mnist_0419.png', 'mnist_0995.png', 'mnist_0468.png', 'mnist_0159.png', 'mnist_0870.png', 'mnist_0205.png', 'mnist_0175.png', 'mnist_0086.png', 'mnist_0163.png', 'mnist_0153.png', 'mnist_0263.png', 'mnist_0814.png', 'mnist_0513.png', 'mnist_0827.png', 'mnist_0603.png', 'mnist_0878.png', 'mnist_0253.png', 'mnist_0369.png', 'mnist_0007.png', 'mnist_0101.png', 'mnist_0520.png', 'mnist_0231.png', 'mnist_0541.png', 'mnist_0950.png', 'mnist_0110.png', 'mnist_0441.png', 'mnist_0662.png', 'mnist_0260.png', 'mnist_0546.png', 'mnist_0728.png', 'mnist_0712.png', 'mnist_0997.png', 'mnist_0493.png', 'mnist_0600.png', 'mnist_0596.png', 'mnist_0932.png', 'mnist_0446.png', 'mnist_0141.png', 'mnist_0705.png', 'mnist_0389.png', 'mnist_0918.png', 'mnist_0955.png', 'mnist_0509.png', 'mnist_0626.png', 'mnist_0732.png', 'mnist_0028.png', 'mnist_0004.png', 'mnist_0661.png', 'mnist_0180.png', 'mnist_0458.png', 'mnist_0430.png', 'mnist_0862.png', 'mnist_0470.png', 'mnist_0385.png', 'mnist_0270.png', 'mnist_0793.png', 'mnist_0482.png', 'mnist_0106.png', 'mnist_0162.png', 'mnist_0494.png', 'mnist_0585.png', 'mnist_0109.png', 'mnist_0167.png', 'mnist_0504.png', 'mnist_0235.png', 'mnist_0454.png', 'mnist_0035.png', 'mnist_0324.png', 'mnist_1000.png', 'mnist_0058.png', 'mnist_0161.png', 'mnist_0158.png', 'mnist_0192.png', 'mnist_0861.png', 'mnist_0856.png', 'mnist_0924.png', 'mnist_0899.png', 'mnist_0031.png', 'mnist_0081.png', 'mnist_0214.png', 'mnist_0026.png', 'mnist_0477.png', 'mnist_0015.png', 'mnist_0654.png', 'mnist_0836.png']\n",
            "['mnist_0614.png', 'mnist_0607.png', 'mnist_0610.png', 'mnist_0542.png', 'mnist_0120.png']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp generated_images/*.png generated_images/fake/"
      ],
      "metadata": {
        "id": "gli4JbdN55jC"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class InceptionV3FeatureExtractor(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        weights = Inception_V3_Weights.IMAGENET1K_V1\n",
        "        self.model = inception_v3(weights=weights)  # ✅ FIX\n",
        "        self.model.eval()\n",
        "\n",
        "        for p in self.model.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        with torch.no_grad():\n",
        "            if x.shape[-1] != 299:\n",
        "                x = F.interpolate(\n",
        "                    x, size=(299, 299),\n",
        "                    mode=\"bilinear\", align_corners=False\n",
        "                )\n",
        "\n",
        "            x = self.model.Conv2d_1a_3x3(x)\n",
        "            x = self.model.Conv2d_2a_3x3(x)\n",
        "            x = self.model.Conv2d_2b_3x3(x)\n",
        "            x = self.model.maxpool1(x)\n",
        "            x = self.model.Conv2d_3b_1x1(x)\n",
        "            x = self.model.Conv2d_4a_3x3(x)\n",
        "            x = self.model.maxpool2(x)\n",
        "            x = self.model.Mixed_5b(x)\n",
        "            x = self.model.Mixed_5c(x)\n",
        "            x = self.model.Mixed_5d(x)\n",
        "            x = self.model.Mixed_6a(x)\n",
        "            x = self.model.Mixed_6b(x)\n",
        "            x = self.model.Mixed_6c(x)\n",
        "            x = self.model.Mixed_6d(x)\n",
        "            x = self.model.Mixed_6e(x)\n",
        "            x = self.model.Mixed_7a(x)\n",
        "            x = self.model.Mixed_7b(x)\n",
        "            x = self.model.Mixed_7c(x)\n",
        "            x = self.model.avgpool(x)\n",
        "\n",
        "            return x.view(x.size(0), -1)  # [B, 2048]\n",
        "\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Image Loader (expects subfolders)\n",
        "# ---------------------------------------------\n",
        "def get_image_loader(folder_path, batch_size=32):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((299, 299)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5]*3, [0.5]*3)\n",
        "    ])\n",
        "\n",
        "    dataset = datasets.ImageFolder(folder_path, transform=transform)\n",
        "    return DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Extract activations\n",
        "# ---------------------------------------------\n",
        "def get_activations(loader, model, device):\n",
        "    feats = []\n",
        "    for imgs, _ in tqdm(loader, desc=\"Extracting features\"):\n",
        "        imgs = imgs.to(device)\n",
        "        feats.append(model(imgs).cpu().numpy())\n",
        "    return np.concatenate(feats, axis=0)\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Frechet Distance\n",
        "# ---------------------------------------------\n",
        "def calculate_frechet_distance(mu1, sigma1, mu2, sigma2):\n",
        "    diff = mu1 - mu2\n",
        "    covmean, _ = linalg.sqrtm(sigma1 @ sigma2, disp=False)\n",
        "\n",
        "    if np.iscomplexobj(covmean):\n",
        "        covmean = covmean.real\n",
        "\n",
        "    return diff @ diff + np.trace(sigma1 + sigma2 - 2 * covmean)\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Main FID function\n",
        "# ---------------------------------------------\n",
        "def compute_fid_from_folders(real_folder, gen_folder, device):\n",
        "    real_loader = get_image_loader(real_folder)\n",
        "    gen_loader = get_image_loader(gen_folder)\n",
        "\n",
        "    model = InceptionV3FeatureExtractor().to(device)\n",
        "\n",
        "    real_feats = get_activations(real_loader, model, device)\n",
        "    gen_feats = get_activations(gen_loader, model, device)\n",
        "\n",
        "    mu1, sigma1 = real_feats.mean(0), np.cov(real_feats, rowvar=False)\n",
        "    mu2, sigma2 = gen_feats.mean(0), np.cov(gen_feats, rowvar=False)\n",
        "\n",
        "    return calculate_frechet_distance(mu1, sigma1, mu2, sigma2)\n",
        "\n",
        "\n",
        "# ---------------------------------------------\n",
        "# Run\n",
        "# ---------------------------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    fid = compute_fid_from_folders(\n",
        "        real_folder=\"real_images\",\n",
        "        gen_folder=\"generated_images\",\n",
        "        device=device\n",
        "    )\n",
        "\n",
        "    print(f\"FID Score: {fid:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jL9z9q3Zi4ii",
        "outputId": "c569fe25-904a-4ad9-e128-49ec2bbd13c1"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/inception_v3_google-0cc3c7bd.pth\" to /root/.cache/torch/hub/checkpoints/inception_v3_google-0cc3c7bd.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 104M/104M [00:00<00:00, 123MB/s] \n",
            "Extracting features: 100%|██████████| 32/32 [00:05<00:00,  6.14it/s]\n",
            "Extracting features: 100%|██████████| 34/34 [00:05<00:00,  6.16it/s]\n",
            "/tmp/ipython-input-1380039855.py:73: DeprecationWarning: The `disp` argument is deprecated and will be removed in SciPy 1.18.0.\n",
            "  covmean, _ = linalg.sqrtm(sigma1 @ sigma2, disp=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FID Score: 48.3179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_dir = os.getcwd()\n",
        "folders = [f for f in os.listdir(current_dir) if os.path.isdir(os.path.join(current_dir, f))]\n",
        "\n",
        "print(\"📁 Folders in current directory:\")\n",
        "for folder in folders:\n",
        "    print(f\" - {folder}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2164ZVtj2Bs",
        "outputId": "bba96d35-6052-42ea-bcd1-8607a87a31bb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📁 Folders in current directory:\n",
            " - .config\n",
            " - generated_images\n",
            " - data\n",
            " - MNIST\n",
            " - real_images\n",
            " - sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "def wrap_in_class_folder(base_dir, class_name=\"class_x\"):\n",
        "    class_dir = os.path.join(base_dir, class_name)\n",
        "    os.makedirs(class_dir, exist_ok=True)\n",
        "\n",
        "    for fname in os.listdir(base_dir):\n",
        "        path = os.path.join(base_dir, fname)\n",
        "        if os.path.isfile(path):\n",
        "            shutil.move(path, os.path.join(class_dir, fname))\n",
        "\n",
        "# Example usage\n",
        "wrap_in_class_folder(\"real_images\")\n",
        "wrap_in_class_folder(\"generated_images\")"
      ],
      "metadata": {
        "id": "h1IPI5rakRlf"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "for folder in [\"real_images\", \"generated_images\"]:\n",
        "    checkpoints = os.path.join(folder, \".ipynb_checkpoints\")\n",
        "    if os.path.exists(checkpoints):\n",
        "        shutil.rmtree(checkpoints)\n",
        "        print(f\"Removed: {checkpoints}\")"
      ],
      "metadata": {
        "id": "mQlpIKeMkh_P"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "baMpEEPx6cXV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}