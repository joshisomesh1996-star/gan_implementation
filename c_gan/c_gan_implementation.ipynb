{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOPgW3cr7KwY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "batch_size = 128\n",
        "z_dim = 100\n",
        "num_classes = 10\n",
        "img_size = 28\n",
        "channels = 1\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "beta1 = 0.5\n",
        "\n",
        "os.makedirs(\"cgan_generated\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5], [0.5])\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('.', train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7T02Cp3-Nqm",
        "outputId": "300100f6-ecbe-45f1-cfd6-3828097f36b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:02<00:00, 4.08MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 134kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:01<00:00, 1.24MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 11.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, img_shape):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.img_shape = img_shape\n",
        "        input_dim = z_dim + num_classes\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Linear(1024, int(torch.prod(torch.tensor(img_shape)))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "        # Concatenate noise and label embedding\n",
        "        x = torch.cat([noise, self.label_emb(labels)], dim=1)\n",
        "        img = self.model(x)\n",
        "        img = img.view(x.size(0), *self.img_shape)\n",
        "        return img"
      ],
      "metadata": {
        "id": "pD8-nOkn-P6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, num_classes, img_shape):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        input_dim = int(torch.prod(torch.tensor(img_shape))) + num_classes\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(512, 256),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "            nn.Linear(256, 1),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, img, labels):\n",
        "        # Flatten image and concatenate label\n",
        "        img_flat = img.view(img.size(0), -1)\n",
        "        x = torch.cat([img_flat, self.label_emb(labels)], dim=1)\n",
        "        return self.model(x)"
      ],
      "metadata": {
        "id": "D5c_qDJS-Rzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (channels, img_size, img_size)\n",
        "\n",
        "generator = Generator(z_dim, num_classes, img_shape).to(device)\n",
        "discriminator = Discriminator(num_classes, img_shape).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))"
      ],
      "metadata": {
        "id": "-PwUENqG-UWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3  # Generator updates per iteration\n",
        "p = 1  # Discriminator updates per iteration"
      ],
      "metadata": {
        "id": "WjWeivAr-7qU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "    for i, (real_imgs, real_labels) in enumerate(train_loader):\n",
        "        batch_size_curr = real_imgs.size(0)\n",
        "        real_imgs = real_imgs.to(device)\n",
        "        real_labels = real_labels.to(device)\n",
        "\n",
        "        real = torch.ones(batch_size_curr, 1, device=device)\n",
        "        fake = torch.zeros(batch_size_curr, 1, device=device)\n",
        "\n",
        "        ### ---- Train Discriminator p times ---- ###\n",
        "        for _ in range(p):\n",
        "            z = torch.randn(batch_size_curr, z_dim, device=device)\n",
        "            fake_labels = torch.randint(0, num_classes, (batch_size_curr,), device=device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                gen_imgs = generator(z, fake_labels)\n",
        "\n",
        "            # Real images\n",
        "            real_validity = discriminator(real_imgs, real_labels)\n",
        "            d_real_loss = criterion(real_validity, real)\n",
        "\n",
        "            # Fake images\n",
        "            fake_validity = discriminator(gen_imgs.detach(), fake_labels)\n",
        "            d_fake_loss = criterion(fake_validity, fake)\n",
        "\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "            optimizer_D.zero_grad()\n",
        "            d_loss.backward()\n",
        "            optimizer_D.step()\n",
        "\n",
        "        ### ---- Train Generator k times ---- ###\n",
        "        for _ in range(k):\n",
        "            z = torch.randn(batch_size_curr, z_dim, device=device)\n",
        "            gen_labels = torch.randint(0, num_classes, (batch_size_curr,), device=device)\n",
        "            gen_imgs = generator(z, gen_labels)\n",
        "\n",
        "            # Try to fool the discriminator\n",
        "            validity = discriminator(gen_imgs, gen_labels)\n",
        "            g_loss = criterion(validity, real)  # want D(G(z)) = 1\n",
        "\n",
        "            optimizer_G.zero_grad()\n",
        "            g_loss.backward()\n",
        "            optimizer_G.step()\n",
        "\n",
        "        # Print progress\n",
        "        if i % 200 == 0:\n",
        "            print(f\"[Epoch {epoch}/{epochs}] [Batch {i}/{len(train_loader)}] \"\n",
        "                  f\"D Loss: {d_loss.item():.4f} | G Loss: {g_loss.item():.4f}\")\n",
        "\n",
        "    # Save example images after each epoch\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "        z = torch.randn(10, z_dim, device=device)\n",
        "        labels = torch.arange(0, 10, dtype=torch.long, device=device)\n",
        "        samples = generator(z, labels)\n",
        "        samples = samples * 0.5 + 0.5  # Denormalize\n",
        "        save_image(samples, f\"cgan_generated/epoch_{epoch}.png\", nrow=10)\n",
        "    generator.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3qsvRA9-WiO",
        "outputId": "645cc2aa-2891-4b77-dce9-75c2a5bfe001"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] [Batch 0/469] D Loss: 1.2939 | G Loss: 0.5770\n",
            "[Epoch 1/50] [Batch 200/469] D Loss: 1.4065 | G Loss: 0.6220\n",
            "[Epoch 1/50] [Batch 400/469] D Loss: 1.4308 | G Loss: 0.6320\n",
            "[Epoch 2/50] [Batch 0/469] D Loss: 1.4216 | G Loss: 0.6631\n",
            "[Epoch 2/50] [Batch 200/469] D Loss: 1.3714 | G Loss: 0.6659\n",
            "[Epoch 2/50] [Batch 400/469] D Loss: 1.3584 | G Loss: 0.7126\n",
            "[Epoch 3/50] [Batch 0/469] D Loss: 1.3795 | G Loss: 0.6752\n",
            "[Epoch 3/50] [Batch 200/469] D Loss: 1.3812 | G Loss: 0.7017\n",
            "[Epoch 3/50] [Batch 400/469] D Loss: 1.3930 | G Loss: 0.6747\n",
            "[Epoch 4/50] [Batch 0/469] D Loss: 1.4088 | G Loss: 0.6872\n",
            "[Epoch 4/50] [Batch 200/469] D Loss: 1.3936 | G Loss: 0.6979\n",
            "[Epoch 4/50] [Batch 400/469] D Loss: 1.3648 | G Loss: 0.7316\n",
            "[Epoch 5/50] [Batch 0/469] D Loss: 1.3395 | G Loss: 0.7351\n",
            "[Epoch 5/50] [Batch 200/469] D Loss: 1.3856 | G Loss: 0.7334\n",
            "[Epoch 5/50] [Batch 400/469] D Loss: 1.4012 | G Loss: 0.6907\n",
            "[Epoch 6/50] [Batch 0/469] D Loss: 1.3312 | G Loss: 0.6762\n",
            "[Epoch 6/50] [Batch 200/469] D Loss: 1.3929 | G Loss: 0.6845\n",
            "[Epoch 6/50] [Batch 400/469] D Loss: 1.3953 | G Loss: 0.7083\n",
            "[Epoch 7/50] [Batch 0/469] D Loss: 1.3923 | G Loss: 0.7197\n",
            "[Epoch 7/50] [Batch 200/469] D Loss: 1.3237 | G Loss: 0.7259\n",
            "[Epoch 7/50] [Batch 400/469] D Loss: 1.3937 | G Loss: 0.6644\n",
            "[Epoch 8/50] [Batch 0/469] D Loss: 1.4203 | G Loss: 0.7182\n",
            "[Epoch 8/50] [Batch 200/469] D Loss: 1.3767 | G Loss: 0.7199\n",
            "[Epoch 8/50] [Batch 400/469] D Loss: 1.3768 | G Loss: 0.6937\n",
            "[Epoch 9/50] [Batch 0/469] D Loss: 1.3637 | G Loss: 0.7570\n",
            "[Epoch 9/50] [Batch 200/469] D Loss: 1.3504 | G Loss: 0.7052\n",
            "[Epoch 9/50] [Batch 400/469] D Loss: 1.3525 | G Loss: 0.7178\n",
            "[Epoch 10/50] [Batch 0/469] D Loss: 1.4084 | G Loss: 0.7341\n",
            "[Epoch 10/50] [Batch 200/469] D Loss: 1.3464 | G Loss: 0.7582\n",
            "[Epoch 10/50] [Batch 400/469] D Loss: 1.4043 | G Loss: 0.7093\n",
            "[Epoch 11/50] [Batch 0/469] D Loss: 1.3493 | G Loss: 0.7736\n",
            "[Epoch 11/50] [Batch 200/469] D Loss: 1.4515 | G Loss: 0.7046\n",
            "[Epoch 11/50] [Batch 400/469] D Loss: 1.3987 | G Loss: 0.6687\n",
            "[Epoch 12/50] [Batch 0/469] D Loss: 1.4476 | G Loss: 0.6806\n",
            "[Epoch 12/50] [Batch 200/469] D Loss: 1.3610 | G Loss: 0.7441\n",
            "[Epoch 12/50] [Batch 400/469] D Loss: 1.3144 | G Loss: 0.6934\n",
            "[Epoch 13/50] [Batch 0/469] D Loss: 1.3809 | G Loss: 0.6821\n",
            "[Epoch 13/50] [Batch 200/469] D Loss: 1.4467 | G Loss: 0.6958\n",
            "[Epoch 13/50] [Batch 400/469] D Loss: 1.3533 | G Loss: 0.7105\n",
            "[Epoch 14/50] [Batch 0/469] D Loss: 1.3767 | G Loss: 0.7410\n",
            "[Epoch 14/50] [Batch 200/469] D Loss: 1.3658 | G Loss: 0.8491\n",
            "[Epoch 14/50] [Batch 400/469] D Loss: 1.3541 | G Loss: 0.6995\n",
            "[Epoch 15/50] [Batch 0/469] D Loss: 1.3042 | G Loss: 0.7804\n",
            "[Epoch 15/50] [Batch 200/469] D Loss: 1.2855 | G Loss: 0.7776\n",
            "[Epoch 15/50] [Batch 400/469] D Loss: 1.3565 | G Loss: 0.6719\n",
            "[Epoch 16/50] [Batch 0/469] D Loss: 1.3568 | G Loss: 0.7501\n",
            "[Epoch 16/50] [Batch 200/469] D Loss: 1.3415 | G Loss: 0.7443\n",
            "[Epoch 16/50] [Batch 400/469] D Loss: 1.3491 | G Loss: 0.8598\n",
            "[Epoch 17/50] [Batch 0/469] D Loss: 1.3822 | G Loss: 1.0090\n",
            "[Epoch 17/50] [Batch 200/469] D Loss: 1.3347 | G Loss: 0.6998\n",
            "[Epoch 17/50] [Batch 400/469] D Loss: 1.3617 | G Loss: 0.8525\n",
            "[Epoch 18/50] [Batch 0/469] D Loss: 1.2732 | G Loss: 0.8986\n",
            "[Epoch 18/50] [Batch 200/469] D Loss: 1.3690 | G Loss: 0.7235\n",
            "[Epoch 18/50] [Batch 400/469] D Loss: 1.4567 | G Loss: 0.7898\n",
            "[Epoch 19/50] [Batch 0/469] D Loss: 1.3643 | G Loss: 0.6638\n",
            "[Epoch 19/50] [Batch 200/469] D Loss: 1.4023 | G Loss: 0.5909\n",
            "[Epoch 19/50] [Batch 400/469] D Loss: 1.3056 | G Loss: 0.7298\n",
            "[Epoch 20/50] [Batch 0/469] D Loss: 1.4783 | G Loss: 0.9821\n",
            "[Epoch 20/50] [Batch 200/469] D Loss: 1.3115 | G Loss: 0.6853\n",
            "[Epoch 20/50] [Batch 400/469] D Loss: 1.3362 | G Loss: 0.6960\n",
            "[Epoch 21/50] [Batch 0/469] D Loss: 1.3428 | G Loss: 0.9051\n",
            "[Epoch 21/50] [Batch 200/469] D Loss: 1.3614 | G Loss: 0.6485\n",
            "[Epoch 21/50] [Batch 400/469] D Loss: 1.2803 | G Loss: 0.7246\n",
            "[Epoch 22/50] [Batch 0/469] D Loss: 1.3179 | G Loss: 0.8035\n",
            "[Epoch 22/50] [Batch 200/469] D Loss: 1.3261 | G Loss: 0.7921\n",
            "[Epoch 22/50] [Batch 400/469] D Loss: 1.3554 | G Loss: 0.7419\n",
            "[Epoch 23/50] [Batch 0/469] D Loss: 1.3426 | G Loss: 0.7942\n",
            "[Epoch 23/50] [Batch 200/469] D Loss: 1.4124 | G Loss: 0.7987\n",
            "[Epoch 23/50] [Batch 400/469] D Loss: 1.2593 | G Loss: 0.7734\n",
            "[Epoch 24/50] [Batch 0/469] D Loss: 1.3574 | G Loss: 0.7794\n",
            "[Epoch 24/50] [Batch 200/469] D Loss: 1.4266 | G Loss: 0.6562\n",
            "[Epoch 24/50] [Batch 400/469] D Loss: 1.2968 | G Loss: 0.8285\n",
            "[Epoch 25/50] [Batch 0/469] D Loss: 1.3265 | G Loss: 0.7509\n",
            "[Epoch 25/50] [Batch 200/469] D Loss: 1.3514 | G Loss: 0.8359\n",
            "[Epoch 25/50] [Batch 400/469] D Loss: 1.3462 | G Loss: 0.7577\n",
            "[Epoch 26/50] [Batch 0/469] D Loss: 1.4100 | G Loss: 0.9137\n",
            "[Epoch 26/50] [Batch 200/469] D Loss: 1.3204 | G Loss: 0.7236\n",
            "[Epoch 26/50] [Batch 400/469] D Loss: 1.2509 | G Loss: 0.6718\n",
            "[Epoch 27/50] [Batch 0/469] D Loss: 1.2836 | G Loss: 0.8427\n",
            "[Epoch 27/50] [Batch 200/469] D Loss: 1.2518 | G Loss: 0.8639\n",
            "[Epoch 27/50] [Batch 400/469] D Loss: 1.1703 | G Loss: 0.8928\n",
            "[Epoch 28/50] [Batch 0/469] D Loss: 1.3164 | G Loss: 0.9072\n",
            "[Epoch 28/50] [Batch 200/469] D Loss: 1.3342 | G Loss: 0.5390\n",
            "[Epoch 28/50] [Batch 400/469] D Loss: 1.3697 | G Loss: 0.7860\n",
            "[Epoch 29/50] [Batch 0/469] D Loss: 1.3902 | G Loss: 0.7968\n",
            "[Epoch 29/50] [Batch 200/469] D Loss: 1.3416 | G Loss: 0.7831\n",
            "[Epoch 29/50] [Batch 400/469] D Loss: 1.2601 | G Loss: 1.3959\n",
            "[Epoch 30/50] [Batch 0/469] D Loss: 1.2683 | G Loss: 0.7870\n",
            "[Epoch 30/50] [Batch 200/469] D Loss: 1.2308 | G Loss: 0.6736\n",
            "[Epoch 30/50] [Batch 400/469] D Loss: 1.3208 | G Loss: 0.9308\n",
            "[Epoch 31/50] [Batch 0/469] D Loss: 1.2460 | G Loss: 0.7795\n",
            "[Epoch 31/50] [Batch 200/469] D Loss: 1.2920 | G Loss: 0.9699\n",
            "[Epoch 31/50] [Batch 400/469] D Loss: 1.2441 | G Loss: 0.8330\n",
            "[Epoch 32/50] [Batch 0/469] D Loss: 1.2544 | G Loss: 0.7549\n",
            "[Epoch 32/50] [Batch 200/469] D Loss: 1.2355 | G Loss: 0.9209\n",
            "[Epoch 32/50] [Batch 400/469] D Loss: 1.3164 | G Loss: 0.9994\n",
            "[Epoch 33/50] [Batch 0/469] D Loss: 1.2415 | G Loss: 0.9604\n",
            "[Epoch 33/50] [Batch 200/469] D Loss: 1.2699 | G Loss: 0.9163\n",
            "[Epoch 33/50] [Batch 400/469] D Loss: 1.1273 | G Loss: 1.0169\n",
            "[Epoch 34/50] [Batch 0/469] D Loss: 1.5513 | G Loss: 0.3988\n",
            "[Epoch 34/50] [Batch 200/469] D Loss: 1.3098 | G Loss: 0.9080\n",
            "[Epoch 34/50] [Batch 400/469] D Loss: 1.2991 | G Loss: 0.8065\n",
            "[Epoch 35/50] [Batch 0/469] D Loss: 1.1809 | G Loss: 0.7922\n",
            "[Epoch 35/50] [Batch 200/469] D Loss: 1.1768 | G Loss: 0.6845\n",
            "[Epoch 35/50] [Batch 400/469] D Loss: 1.2671 | G Loss: 0.8985\n",
            "[Epoch 36/50] [Batch 0/469] D Loss: 1.2293 | G Loss: 1.0387\n",
            "[Epoch 36/50] [Batch 200/469] D Loss: 1.3251 | G Loss: 0.8094\n",
            "[Epoch 36/50] [Batch 400/469] D Loss: 1.1127 | G Loss: 1.0689\n",
            "[Epoch 37/50] [Batch 0/469] D Loss: 1.2006 | G Loss: 1.0568\n",
            "[Epoch 37/50] [Batch 200/469] D Loss: 1.2625 | G Loss: 0.8142\n",
            "[Epoch 37/50] [Batch 400/469] D Loss: 1.2800 | G Loss: 1.1308\n",
            "[Epoch 38/50] [Batch 0/469] D Loss: 1.2513 | G Loss: 1.1761\n",
            "[Epoch 38/50] [Batch 200/469] D Loss: 1.1817 | G Loss: 1.0999\n",
            "[Epoch 38/50] [Batch 400/469] D Loss: 1.0977 | G Loss: 0.8990\n",
            "[Epoch 39/50] [Batch 0/469] D Loss: 1.1158 | G Loss: 1.0466\n",
            "[Epoch 39/50] [Batch 200/469] D Loss: 1.2658 | G Loss: 0.8356\n",
            "[Epoch 39/50] [Batch 400/469] D Loss: 1.2414 | G Loss: 0.7786\n",
            "[Epoch 40/50] [Batch 0/469] D Loss: 1.1814 | G Loss: 1.0193\n",
            "[Epoch 40/50] [Batch 200/469] D Loss: 1.3630 | G Loss: 0.8604\n",
            "[Epoch 40/50] [Batch 400/469] D Loss: 1.3354 | G Loss: 0.9208\n",
            "[Epoch 41/50] [Batch 0/469] D Loss: 1.1349 | G Loss: 1.1354\n",
            "[Epoch 41/50] [Batch 200/469] D Loss: 1.3430 | G Loss: 0.7390\n",
            "[Epoch 41/50] [Batch 400/469] D Loss: 1.2850 | G Loss: 1.2572\n",
            "[Epoch 42/50] [Batch 0/469] D Loss: 1.3957 | G Loss: 0.7231\n",
            "[Epoch 42/50] [Batch 200/469] D Loss: 1.1990 | G Loss: 0.8642\n",
            "[Epoch 42/50] [Batch 400/469] D Loss: 1.3237 | G Loss: 0.7038\n",
            "[Epoch 43/50] [Batch 0/469] D Loss: 1.2983 | G Loss: 1.0544\n",
            "[Epoch 43/50] [Batch 200/469] D Loss: 1.2791 | G Loss: 0.9652\n",
            "[Epoch 43/50] [Batch 400/469] D Loss: 1.2412 | G Loss: 0.8292\n",
            "[Epoch 44/50] [Batch 0/469] D Loss: 1.3295 | G Loss: 1.1055\n",
            "[Epoch 44/50] [Batch 200/469] D Loss: 1.3884 | G Loss: 0.9977\n",
            "[Epoch 44/50] [Batch 400/469] D Loss: 1.2568 | G Loss: 0.7666\n",
            "[Epoch 45/50] [Batch 0/469] D Loss: 1.2279 | G Loss: 0.9238\n",
            "[Epoch 45/50] [Batch 200/469] D Loss: 1.2762 | G Loss: 1.0230\n",
            "[Epoch 45/50] [Batch 400/469] D Loss: 1.4058 | G Loss: 1.1008\n",
            "[Epoch 46/50] [Batch 0/469] D Loss: 1.4043 | G Loss: 0.8380\n",
            "[Epoch 46/50] [Batch 200/469] D Loss: 1.2487 | G Loss: 1.0137\n",
            "[Epoch 46/50] [Batch 400/469] D Loss: 1.2772 | G Loss: 0.9023\n",
            "[Epoch 47/50] [Batch 0/469] D Loss: 1.2671 | G Loss: 0.8870\n",
            "[Epoch 47/50] [Batch 200/469] D Loss: 1.3417 | G Loss: 1.0395\n",
            "[Epoch 47/50] [Batch 400/469] D Loss: 1.2712 | G Loss: 0.9329\n",
            "[Epoch 48/50] [Batch 0/469] D Loss: 1.2648 | G Loss: 1.3150\n",
            "[Epoch 48/50] [Batch 200/469] D Loss: 1.2499 | G Loss: 1.0991\n",
            "[Epoch 48/50] [Batch 400/469] D Loss: 1.2356 | G Loss: 0.9624\n",
            "[Epoch 49/50] [Batch 0/469] D Loss: 1.2462 | G Loss: 1.0123\n",
            "[Epoch 49/50] [Batch 200/469] D Loss: 1.2941 | G Loss: 0.8953\n",
            "[Epoch 49/50] [Batch 400/469] D Loss: 1.2862 | G Loss: 0.9452\n",
            "[Epoch 50/50] [Batch 0/469] D Loss: 1.2992 | G Loss: 0.7740\n",
            "[Epoch 50/50] [Batch 200/469] D Loss: 1.2206 | G Loss: 1.3196\n",
            "[Epoch 50/50] [Batch 400/469] D Loss: 1.3026 | G Loss: 0.8899\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_digit_images(generator, digit, num_samples=16, save_path=None):\n",
        "    generator.eval()\n",
        "    z = torch.randn(num_samples, z_dim).to(device)\n",
        "    labels = torch.full((num_samples,), digit, dtype=torch.long).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        gen_imgs = generator(z, labels)\n",
        "        gen_imgs = gen_imgs * 0.5 + 0.5\n",
        "\n",
        "    if save_path:\n",
        "        save_image(gen_imgs, save_path, nrow=4)\n",
        "        print(f\"Saved to {save_path}\")\n",
        "    return gen_imgs"
      ],
      "metadata": {
        "id": "mSgB8Zy4-YrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 16 samples of digit \"7\"\n",
        "generate_digit_images(generator, digit=7, num_samples=16, save_path=\"cgan_generated/seven.png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1EPk-t-Q-ani",
        "outputId": "d9050117-ad1b-4e72-e695-5e8468a403c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to cgan_generated/seven.png\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.0000e+00, 1.2219e-06, 2.9504e-06,  ..., 4.7386e-06,\n",
              "           1.2219e-06, 2.9802e-08],\n",
              "          [9.5367e-07, 5.9605e-08, 8.2552e-06,  ..., 0.0000e+00,\n",
              "           6.8545e-07, 3.2783e-07],\n",
              "          [4.7684e-07, 2.9802e-08, 3.9190e-05,  ..., 0.0000e+00,\n",
              "           9.5367e-07, 2.2948e-06],\n",
              "          ...,\n",
              "          [8.9407e-08, 5.9605e-08, 5.9605e-08,  ..., 5.9605e-07,\n",
              "           5.9605e-08, 8.9407e-08],\n",
              "          [8.9586e-05, 4.7684e-06, 4.7445e-05,  ..., 8.9407e-08,\n",
              "           0.0000e+00, 8.9407e-08],\n",
              "          [2.9802e-08, 7.1824e-06, 1.7881e-07,  ..., 3.6508e-05,\n",
              "           4.1723e-07, 2.0862e-07]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0133e-06, 2.6226e-06,  ..., 3.6061e-06,\n",
              "           9.8348e-07, 2.9802e-08],\n",
              "          [8.0466e-07, 5.9605e-08, 7.0035e-06,  ..., 0.0000e+00,\n",
              "           5.9605e-07, 2.6822e-07],\n",
              "          [4.7684e-07, 2.9802e-08, 3.2127e-05,  ..., 0.0000e+00,\n",
              "           8.3447e-07, 1.9968e-06],\n",
              "          ...,\n",
              "          [5.9605e-08, 5.9605e-08, 5.9605e-08,  ..., 5.0664e-07,\n",
              "           5.9605e-08, 8.9407e-08],\n",
              "          [7.9691e-05, 3.9041e-06, 4.8548e-05,  ..., 8.9407e-08,\n",
              "           0.0000e+00, 5.9605e-08],\n",
              "          [2.9802e-08, 5.6028e-06, 1.7881e-07,  ..., 2.9385e-05,\n",
              "           3.8743e-07, 2.0862e-07]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.0133e-06, 2.4438e-06,  ..., 3.5763e-06,\n",
              "           9.5367e-07, 2.9802e-08],\n",
              "          [8.3447e-07, 2.9802e-08, 6.6459e-06,  ..., 0.0000e+00,\n",
              "           4.7684e-07, 2.3842e-07],\n",
              "          [3.2783e-07, 2.9802e-08, 3.3945e-05,  ..., 0.0000e+00,\n",
              "           9.2387e-07, 1.4603e-06],\n",
              "          ...,\n",
              "          [5.9605e-08, 5.9605e-08, 5.9605e-08,  ..., 4.7684e-07,\n",
              "           5.9605e-08, 5.9605e-08],\n",
              "          [8.2314e-05, 3.8147e-06, 3.7044e-05,  ..., 5.9605e-08,\n",
              "           0.0000e+00, 5.9605e-08],\n",
              "          [2.9802e-08, 6.1393e-06, 1.4901e-07,  ..., 2.8670e-05,\n",
              "           3.5763e-07, 1.4901e-07]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 1.3709e-06, 3.2783e-06,  ..., 4.6790e-06,\n",
              "           1.1921e-06, 2.9802e-08],\n",
              "          [8.3447e-07, 5.9605e-08, 7.3016e-06,  ..., 0.0000e+00,\n",
              "           8.3447e-07, 3.2783e-07],\n",
              "          [4.7684e-07, 2.9802e-08, 3.7700e-05,  ..., 0.0000e+00,\n",
              "           1.1325e-06, 2.4438e-06],\n",
              "          ...,\n",
              "          [8.9407e-08, 5.9605e-08, 5.9605e-08,  ..., 5.6624e-07,\n",
              "           5.9605e-08, 1.1921e-07],\n",
              "          [9.0301e-05, 4.6492e-06, 5.1796e-05,  ..., 8.9407e-08,\n",
              "           0.0000e+00, 8.9407e-08],\n",
              "          [2.9802e-08, 6.8843e-06, 2.0862e-07,  ..., 3.3915e-05,\n",
              "           4.7684e-07, 2.0862e-07]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 9.5367e-07, 2.1160e-06,  ..., 3.1590e-06,\n",
              "           8.0466e-07, 2.9802e-08],\n",
              "          [7.7486e-07, 2.9802e-08, 6.2585e-06,  ..., 0.0000e+00,\n",
              "           5.6624e-07, 2.3842e-07],\n",
              "          [3.8743e-07, 2.9802e-08, 3.5852e-05,  ..., 0.0000e+00,\n",
              "           8.0466e-07, 1.5497e-06],\n",
              "          ...,\n",
              "          [5.9605e-08, 5.9605e-08, 2.9802e-08,  ..., 4.7684e-07,\n",
              "           5.9605e-08, 8.9407e-08],\n",
              "          [7.4148e-05, 3.3379e-06, 4.4286e-05,  ..., 8.9407e-08,\n",
              "           0.0000e+00, 5.9605e-08],\n",
              "          [2.9802e-08, 5.7220e-06, 1.4901e-07,  ..., 2.8193e-05,\n",
              "           3.5763e-07, 1.4901e-07]]],\n",
              "\n",
              "\n",
              "        [[[0.0000e+00, 9.8348e-07, 2.0564e-06,  ..., 3.1292e-06,\n",
              "           8.9407e-07, 2.9802e-08],\n",
              "          [8.3447e-07, 5.9605e-08, 6.2585e-06,  ..., 0.0000e+00,\n",
              "           5.6624e-07, 2.3842e-07],\n",
              "          [4.1723e-07, 2.9802e-08, 3.4571e-05,  ..., 0.0000e+00,\n",
              "           8.0466e-07, 1.4901e-06],\n",
              "          ...,\n",
              "          [5.9605e-08, 2.9802e-08, 5.9605e-08,  ..., 5.3644e-07,\n",
              "           5.9605e-08, 8.9407e-08],\n",
              "          [7.4178e-05, 3.8147e-06, 4.3780e-05,  ..., 5.9605e-08,\n",
              "           0.0000e+00, 5.9605e-08],\n",
              "          [2.9802e-08, 5.4538e-06, 1.4901e-07,  ..., 2.5481e-05,\n",
              "           3.8743e-07, 1.4901e-07]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r cgan_generated.zip cgan_generated/"
      ],
      "metadata": {
        "id": "zWY_098_AvP4",
        "outputId": "bc87b267-29bd-40b3-eb44-93245a23ccff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: cgan_generated/ (stored 0%)\n",
            "  adding: cgan_generated/epoch_46.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_11.png (deflated 2%)\n",
            "  adding: cgan_generated/epoch_44.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_47.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_5.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_26.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_15.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_12.png (deflated 1%)\n",
            "  adding: cgan_generated/seven.png (deflated 2%)\n",
            "  adding: cgan_generated/epoch_25.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_38.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_6.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_43.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_14.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_35.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_27.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_22.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_30.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_4.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_48.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_37.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_36.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_41.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_50.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_17.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_16.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_20.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_42.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_24.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_18.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_49.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_23.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_7.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_29.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_34.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_39.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_1.png (deflated 4%)\n",
            "  adding: cgan_generated/epoch_10.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_31.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_8.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_28.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_21.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_3.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_32.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_19.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_45.png (deflated 1%)\n",
            "  adding: cgan_generated/epoch_13.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_2.png (deflated 2%)\n",
            "  adding: cgan_generated/epoch_9.png (stored 0%)\n",
            "  adding: cgan_generated/epoch_40.png (deflated 0%)\n",
            "  adding: cgan_generated/epoch_33.png (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N0VGFdwEAwrO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}